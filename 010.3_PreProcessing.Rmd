---
output: html_document
---

<body id="start">
<div class="topnav">
  <a href='index.html#Frontpage'>Frontpage</a>
  <a href='data-visualisation.html#data-visualisation'>Data visualisation</a>
  <a href='parametized-data-germany.html#parametized-data'>Parametizing data</a>
  <a href='directory-structure.html#directory-structure'>Directory structure</a>
  <a href='creating-a-r-package.html#creating-a-r-package'>R-package</a>
  <a href='sql.html#SQL'>SQL</a>
  <a href='bibliography-using-zotero.html#Bibliography using Zotero'>Zotero</a>
  <a href='open-reproductibility-analysis.html#open-reproductibility-analysis'>Reproductibility</a>
  <a href='future-endeavours.html#future-endeavours'>Future endeavours</a>
  <a href='new-skills.html#new-skills'> New skills (Machine learning)</a>
  <a href='cv.html#cv'>CV</a>
  <a href='bibliography.html#bibliography'>Bibliography</a>
</div>

```{r, include=FALSE}
library(tidyverse)
library(ggplot2)
library(gridExtra)
```

&nbsp;

For the studying of pre-processing, we'll use the package called "Karet". caret, short for Classification And REgression Training, is a package containing functions to help create machine learning-based (or actually, any form of predictive) models.

```{r}
library(caret)
names(getModelInfo()) %>% head(50)
```

Caret contains _a lot_ of predictive models: above are shown only the top 50 of the over 200 models available in caret. For now we'll continue to use a KNN model, though we'll study another model later too.

First of all, we can use "createDataPartition" instead of "sample" to create a training and a test group more easily

```{r}
set.seed(1234)
index<-createDataPartition(iris$Species, p=0.75, list=FALSE)

iris_training2<-iris[index,]

iris_test2<-iris[-index,]
```

Now, with the training data separated, we can use the caret-method of training a model and predicting with it

```{r}
model_knn<-train(iris_training2[,1:4], iris_training2[,5], method='knn')

#Then, we use the model to make a prediction
prediction<-predict(object=model_knn, iris_test2[,1:4])

#We check if the predicitons are true
pred<-prediction == iris_test2[,5]
table(pred)
```

And, due to the fact that we're using caret, we can create a confusion matrix: this'll allow us to study the sensitivity and the specificity of our model way easier.

```{r}
#And we create a confusion matrix for the results
confusionMatrix(prediction,iris_test2[,5])
```

We can see that the model can identify Setosa perfectly, but struggles a little with versicolor (92% accuracy) and some more with virginica (83% accuracy).

What's nice about caret training is that it contains pre-built in preprocessing methods. For the most basic examples of pre-processing, take centering and scaling.

- Centering is a form of pre-processing where the mean of the data is determined, and all other data is represented based on their distance to the mean

- Scaling is a form of pre-processing where all data is changed to the same scale of size. This makes sure the machine learning algorythm does not determine that one variable is more important than another, purely because it has higher numbers.

```{r}
model_knn<-train(iris_training2[,1:4],iris_training2[,5],method='knn',preProcess = c("center", "scale"))

prediction<-predict(object=model_knn, iris_test2[,1:4], type='raw')

pred<-prediction == iris_test2[,5]
table(pred)

confusionMatrix(prediction, iris_test2[,5])
```

centering and scaling the data already increases the accuracy of the system, making it detect the versicolor originally classified as a virginica as the correct species. To further explore the power of pre-processing, we'll take our home-made Glass KNN-model again, re-make it in caret, and pre-process the data before applying the model.

```{r}

```


