--- 
title: "Portfolio Pedro de Bos"
site: bookdown::bookdown_site
output: 
  bookdown::html_book:
    toc: FALSE
    number_sections: FALSE
documentclass: book
link-citations: yes
css: style.css
bibliography: references.bib
---

# Frontpage

Placeholder



<!--chapter:end:index.Rmd-->


# Data visualisation

Placeholder



<!--chapter:end:002_DataVisualisation.Rmd-->


# Parametized Data Norway

Placeholder



<!--chapter:end:003_02_ParametizedData.Rmd-->


# Parametized Data Belgium

Placeholder



<!--chapter:end:003_03_ParametizedData.Rmd-->


# Parametized Data Germany

Placeholder



<!--chapter:end:003_ParametizedData.Rmd-->


# Directory structure

Placeholder



<!--chapter:end:004_DirectoryStructure.Rmd-->


# Creating a R package

Placeholder



<!--chapter:end:005_RPackage.Rmd-->


# SQL

Placeholder



<!--chapter:end:006_SQL.Rmd-->


# Bibliography using Zotero

Placeholder



<!--chapter:end:007_Zotero.Rmd-->


# Open reproductibility analysis

Placeholder



<!--chapter:end:008_ReproductableResearch.Rmd-->


# Future endeavours

Placeholder



<!--chapter:end:009_PlanForFuture.Rmd-->


# New skills

Placeholder



<!--chapter:end:010.1_CleanFreeRoom.Rmd-->




<!--chapter:end:010.2_KNNSelf.Rmd-->




<!--chapter:end:010.3_PreProcessing.Rmd-->

---
output: html_document
---

<body id="start">
<div class="topnav">
  <a href='index.html#Frontpage'>Frontpage</a>
  <a href='data-visualisation.html#data-visualisation'>Data visualisation</a>
  <a href='parametized-data-germany.html#parametized-data'>Parametizing data</a>
  <a href='directory-structure.html#directory-structure'>Directory structure</a>
  <a href='creating-a-r-package.html#creating-a-r-package'>R-package</a>
  <a href='sql.html#SQL'>SQL</a>
  <a href='bibliography-using-zotero.html#Bibliography using Zotero'>Zotero</a>
  <a href='open-reproductibility-analysis.html#open-reproductibility-analysis'>Reproductibility</a>
  <a href='future-endeavours.html#future-endeavours'>Future endeavours</a>
  <a href='new-skills.html#new-skills'> New skills (Machine learning)</a>
  <a href='cv.html#cv'>CV</a>
  <a href='bibliography.html#bibliography'>Bibliography</a>
</div>

&nbsp;

```{r, include=FALSE}
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(caret)
```


The random forest method works via decision tree classification: a model in which information on nodes. The reference forms a giant "tree" consisting of multiple branching paths, connected by nodes. These nodes contain information which of the branches a individual datapoint should go across. Data goes down the tree untill it no longer has any nodes on the tree or information about itself anymore.

This model, while simple, has very low predictive power. Random Forest works on the same principle as decision tree classification, but instead of taking áll datapoints and áll variables, it takes a random selection of them and performs the tree. It then repeats this process for an X amount of times, and finally combines the results of all different decision trees into a single tree. By doing this, it greatly increases its predictive power, and decreases it's bias.

Now, we'll perform a randomForest analysis in R. Data has been aquired from [an archive of a UCI website](https://archive.ics.uci.edu/ml/machine-learning-databases/car/)

```{r}
library(randomForest)

#Reading the data
car_data<-read.csv("data.raw/car.data", header=FALSE)
```

First, let's take a look at the data: according too the metadata-file given with it, the different values mean:

- V1: Buying price
- V2: Selling price
- V3: Amount of doors
- V4: Amount of people who fit in the car
- V5: Size of the luggage boot
- V6: Estimated safety of the car
- V7: Overal car acceptibility

All of these are set up like factors: With levels like vhigh, high, med, low, etc. Because of this, we'll give them all a appropriate name and transform them into a factor. 

```{r}
colnames(car_data)<-c("BuyingPrice", "Maintenance", "NumDoors", "NumPersons", "BootSpace", "Safety", "Condition")

#Changing "character" data into factor data for all data sets
car_data$BuyingPrice<-factor(car_data$BuyingPrice)
car_data$Maintenance<-factor(car_data$Maintenance)
car_data$NumDoors<-factor(car_data$NumDoors)
car_data$NumPersons<-factor(car_data$NumPersons)
car_data$BootSpace<-factor(car_data$BootSpace)
car_data$Safety<-factor(car_data$Safety)
car_data$Condition<-factor(car_data$Condition)


summary(car_data)
```

According the summary, we can see that Buying price - Safety are all equallty spread, with Condition being the only factor where the 4 different levels have different amounts of expression. Because of this. We'll use this condition as condition for our machine learning algorythm.

As is usual for machine learning, we'll split the data into a training-set and a testing-set.

```{r}
set.seed(100)
partition<-createDataPartition(car_data$Condition, p=0.75, list=FALSE)

car_train<-car_data[partition,]
car_test<-car_data[-partition,]
summary(car_train)
summary(car_test)
```

Now, with the training data properly separated, we'll create a random forest model to determine the "condition" of the car data.

```{r}
Model1<-randomForest(Condition ~ ., data = car_train, importance = TRUE)
Model1

predModel1<-predict(Model1, car_test, type="class")
table(predModel1, car_test[,7])

predModel1Valid<-predict(Model1, car_test, type = "class")
table(predModel1Valid, car_test$Condition)
```

It's as easy as that, we've officially created a randomForest learning algorythm in R! However, as with all machine learning algorythms, there's still much to be tweaked in order to create a optimal algorythm. For example, we can modify the "mtry" and the "ntree", two important variables in randomForest models.

As said before, randomForest uses the same principle as decision tree classification, only moddified by randomness and repeating the process a whole lot. mtry and ntree change the randomness of the program: "Mtry" determines how many informationpoints are used for every "node" a sample has to go past to continue down the identification tree. "Ntree" determines the amount of samples used for every random decision tree that's made. By modifying these values in the creation of the model, we can get a different outcome:

```{r}
Model2<-randomForest(Condition ~ ., data= car_train, ntree = 500, mtry = 6, importance = TRUE)
Model2

predModel2<-predict(Model2, car_test, type="class")
table(predModel2, car_test$Condition)

predModel2Valid<-predict(Model2, car_test, type = "class")
table(predModel2Valid, car_test$Condition)
```
By increasing the mtry to 6 and setting the ntree to 500, we've increased the accuracy of our randomForest program. In order to get a detailed breakdown of whether Model 2 is better than Model 1, randomForest has two built-in functions called "importance" and "varImPlot", which we'll use on both models

```{r}
importance(Model1)
importance(Model2)

varImpPlot(Model1)
varImpPlot(Model2)
```

In these plots, the "MeanDecreaseAccuracy" expresses how much accuracy the model loses when it does _not_ consider the given variable, MeanDecreaseGini expresses measures how important that variable is for the homogeneity of the model. The higher the MeanDecreaseAccuracy/Gini, the more important it is for the model. Based on the significantly higher MeanDecreaseAccuracy in model 2 in comparisson to model 1, we can state that model 2 is indeed more accurate than model 1.

Now we know that a ntree = 500 and a mtry = 6 gives a higher, but what about all other posibilities? It'd be a lot of work to manually test for every single possibility, and determine the one with the highest accuracy. 

```{r}
x=c()
for(i in 1:6){
  print(i)
  Model3<-randomForest(Condition ~ ., data= car_train, ntree = 500, mtry = i, importance = TRUE)
  PredictModel3<-predict(Model3, car_test, type="class")
  x[i]=mean(PredictModel3 == car_test$Condition)
}
data.frame(mtry=1:6,
           prediction_power=x)
```

Based on testing mtry's 1-6 (6 being the maximum, since we only have 6 variables), we can conclude that a mtry = 6 does indeed give us the highest prediction power.

```{r}
y=c()
range<-seq(from = 100, to = 1500, by = 100)
for(i in seq(from = 100, to = 1500, by = 100)){
  print(i)
  Model3<-randomForest(Condition ~ ., data= car_train, ntree = i, mtry = 6, importance = TRUE)
  PredictModel3<-predict(Model3, car_test, type="class")
  y[i]=(mean(PredictModel3 == car_test$Condition))
}

data<-data.frame(prediction_power=y[range],
           ntree=seq(from = 100, to = 1500, by = 100))
data %>% filter(prediction_power==max(y[range]))
```

Based on these results, we can see that 5 different ranges, 100, 200, 600, 700 and 1100, all show the exact same (highest) prediction power. Thus, we can conclude in the 100's range, there is no real big difference between different ntree amounts. Perhaps a logarythmic scale will show more difference?

```{r}
y=c()

length<-c(1 %o% 10^(0:4))
for(i in c(1 %o% 10^(0:4))){
  print(i)
  Model3<-randomForest(Condition ~ ., data= car_train, ntree = i, mtry = 6, importance = TRUE)
  PredictModel3<-predict(Model3, car_test, type="class")
  y[i]=(mean(PredictModel3 == car_test$Condition))
}
data<-data.frame(prediction_power=y[length],
                 ntree=length)
data
```

With this table, we _can_ see that a ntree=1 has a lower predictive power, however, these differences are still quite small. Even still, they're handy to keep in mind. Important to keep in mind is that any numbers in a higher power than 1.000 take significantly mote time to render. Thus, it's the question of all that extra rendering time is worth an (in this case) insignificant difference.

With that, we've succesfully performed a randomForest analysis upon a "cars" dataset. Now, we'll look into a package for R called IDTAXA, which uses randomForest computation to identify bacteria based on their 16sRNA.


<!--chapter:end:010.4_RandomForest.Rmd-->


# New skills

Placeholder



<!--chapter:end:010_FreeRoom.Rmd-->

# CV

<body id="start">
<div class="topnav">
  <a href='index.html#Frontpage'>Frontpage</a>
  <a href='data-visualisation.html#data-visualisation'>Data visualisation</a>
  <a href='parametized-data-germany.html#parametized-data'>Parametizing data</a>
  <a href='directory-structure.html#directory-structure'>Directory structure</a>
  <a href='creating-a-r-package.html#creating-a-r-package'>R-package</a>
  <a href='sql.html#SQL'>SQL</a>
  <a href='bibliography-using-zotero.html#Bibliography using Zotero'>Zotero</a>
  <a href='open-reproductibility-analysis.html#open-reproductibility-analysis'>Reproductibility</a>
  <a href='future-endeavours.html#future-endeavours'>Future endeavours</a>
  <a href='new-skills.html#new-skills'> New skills (Machine learning)</a>
  <a href='cv.html#cv'>CV</a>
  <a href='bibliography.html#bibliography'>Bibliography</a>
</div>


&nbsp;

To create my CV, a package called "vitae", created by "Mitchello Harawild" has been used. This CV .Rmd file is, however, not compatable with bookdown (which was used to create this site). This .RMD generates a pdf, of which a .jpg file has been generated and is shown here. The original .Rmd file can be found in my [public repo](https://github.com/PedroDeBos/PedroDeBos.github.io).

<img src="./images/CV_PedroDeBos1024_1.jpg" style="width:724px;height:1024px" class="center">


<!--chapter:end:011_CV.Rmd-->

# Bibliography

<body id="start">
<div class="topnav">
  <a href='index.html#Frontpage'>Frontpage</a>
  <a href='data-visualisation.html#data-visualisation'>Data visualisation</a>
  <a href='parametized-data-germany.html#parametized-data'>Parametizing data</a>
  <a href='directory-structure.html#directory-structure'>Directory structure</a>
  <a href='creating-a-r-package.html#creating-a-r-package'>R-package</a>
  <a href='sql.html#SQL'>SQL</a>
  <a href='bibliography-using-zotero.html#Bibliography using Zotero'>Zotero</a>
  <a href='open-reproductibility-analysis.html#open-reproductibility-analysis'>Reproductibility</a>
  <a href='future-endeavours.html#future-endeavours'>Future endeavours</a>
  <a href='new-skills.html#new-skills'> New skills (Machine learning)</a>
  <a href='cv.html#cv'>CV</a>
  <a href='bibliography.html#bibliography'>Bibliography</a>
</div>



&nbsp;


Here's a collection of all used references for setting up this portfolio

__Bibliography__

<div id="refs"></div>

<!--chapter:end:012_Bibliography.Rmd-->




<!--chapter:end:10.5_INDEXID.Rmd-->

